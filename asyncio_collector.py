#!/usr/bin/env python3.4
import ipfix.message
import ipfix.ie
import asyncio
import logging
import statistics
import time
try:
    import signal
except ImportError:
    signal = None

mode = 'detection'
if mode == 'dumpsql':
    sqlfile = open('/mnt/tmp/flows.sql', 'a')

loglevel = logging.INFO

log = logging.getLogger(__name__)
formatter = logging.Formatter("%(message)s")
log.setLevel(loglevel)
handler = logging.StreamHandler()
# handler = logging.FileHandler('/tmp/ram/statistics.log')
handler.setLevel(loglevel)
handler.setFormatter(formatter)
log.addHandler(handler)

ipfix.ie.use_iana_default()
ipfix.ie.use_5103_default()

monitor = {}

timer = {}
timer_size = 720
timer_tick = 10

for r in range(timer_size):
    timer[r] = []
rev_timer = list(reversed(range(1, len(timer))))

lock = asyncio.Lock()


def safe_devide(x, y):
    try:
        return float(x) / float(y)
    except ZeroDivisionError:
        return 0.0


def debug(line):
    if loglevel == logging.DEBUG:
        log.debug(line)


class Flow:
    def __init__(self, flow_dict: dict):
        self.timestamp = time.time()
        self.src_ip = flow_dict.get('sourceIPv4Address')
        if self.src_ip:
            self.dst_ip = flow_dict['destinationIPv4Address']
            self.src_port = flow_dict['sourceTransportPort']
            self.dst_port = flow_dict['destinationTransportPort']
            self.up_bytes = flow_dict['octetDeltaCount']
            self.down_bytes = flow_dict['postOctetDeltaCount']
            self.up_pkts = flow_dict['packetDeltaCount']
            self.down_pkts = flow_dict['postPacketDeltaCount']

    def __str__(self):
        return "FLOW: {timestamp} {src_ip} {dst_ip} {src_port} {dst_port}" \
               " {up_pkts} {down_pkts} {up_bytes} {down_bytes}".format(**self.__dict__)

    def csv(self):
        return ','.join(str(self).split()[1:])

    def dump_sql(self):
        if mode == 'dumpsql':
            sqlfile.write("({timestamp},'{src_ip}','{dst_ip}',{src_port},{dst_port}"
                          ",{up_pkts},{down_pkts},{up_bytes},{down_bytes}),\n".format(**self.__dict__))

    def log(self):
        with open('/mnt/tmp/{src_ip}-{src_port}.csv'.format(**self.__dict__), 'a') as logfile:
            logfile.write(self.csv() + '\n')


class Stats:
    def __init__(self, flow: Flow):
        self.ip = flow.src_ip
        self.port = flow.src_port
        self.flows = []
        self.p2p = False
        self.machine = False
        self.bad_pkt_ratio = False
        self.zeus = False
        self.update(flow)

    def __str__(self):
        return "STATS: {0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11}".format(
            time.time(), self.ip, self.port, self.noreply, self.destinations,
            self.sum_up_pkts, self.sum_down_pkts, self.sum_up_bytes, self.sum_down_bytes,
            self.avg_up_bytes_pkt, self.avg_down_bytes_pkt, self.pkt_ratio
        )

    def csv(self):
        return ','.join(str(self).split()[1:])

    def log(self):
        with open('/mnt/tmp/{ip}-{port}.csv'.format(**self.__dict__), 'a') as logfile:
            logfile.write(self.csv() + '\n')

    def up_pkts(self):
        return (flow.up_pkts for flow in self.flows)

    def down_pkts(self):
        return (flow.down_pkts for flow in self.flows)

    def up_bytes(self):
        return (flow.up_bytes for flow in self.flows)

    def down_bytes(self):
        return (flow.down_bytes for flow in self.flows)

    @property
    def sum_up_bytes(self):
        return sum(self.up_bytes())

    @property
    def sum_down_bytes(self):
        return sum(self.down_bytes())

    @property
    def sum_up_pkts(self):
        return sum(self.up_pkts())

    @property
    def sum_down_pkts(self):
        return sum(self.down_pkts())

    @property
    def avg_up_bytes_pkt(self):
        return safe_devide(self.sum_up_bytes, self.sum_up_pkts)

    @property
    def avg_down_bytes_pkt(self):
        return safe_devide(self.sum_down_bytes, self.sum_down_pkts)

    @property
    def mean_up_pkts(self):
        return statistics.mean(self.up_pkts())

    @property
    def mean_down_pkts(self):
        return statistics.mean(self.down_pkts())

    @property
    def mean_up_bytes(self):
        return statistics.mean(self.up_bytes())

    @property
    def mean_down_bytes(self):
        return statistics.mean(self.down_bytes())

    @property
    def stdev_up_pkts(self):
        return statistics.stdev(self.up_pkts())

    @property
    def stdev_down_pkts(self):
        return statistics.stdev(self.down_pkts())

    @property
    def stdev_up_bytes(self):
        return statistics.stdev(self.up_bytes())

    @property
    def stdev_down_bytes(self):
        return statistics.stdev(self.down_bytes())

    @property
    def pkt_ratio(self):
        up = float(self.sum_up_pkts)
        down = float(self.sum_down_pkts)
        if up > 2 and down > 2:
            return up / down
        else:
            return 1.0

    @property
    def noreply(self):
        return len(set((flow.dst_ip, flow.dst_port) for flow in self.flows if flow.up_pkts > 0 and flow.down_pkts == 0))

    @property
    def destinations(self):
        return len(set((flow.dst_ip, flow.dst_port) for flow in self.flows))

    @property
    def noreply_percentage(self):
        return safe_devide(self.destinations, self.noreply) * 100

    @property
    def empty(self):
        a = self.noreply_percentage
        print(a)
        return self.flows == []

    def update(self, flow):
        self.flows.append(flow)
        self.detect()

    def expire(self, flow):
        self.flows.remove(flow)

    def detect(self):
        debug(self)

        if not self.p2p:
            self.detect_p2p()

        if not self.bad_pkt_ratio:
            self.detect_bad_pkt_ratio()

        if not self.machine:
            self.detect_machine()

        if not self.zeus:
            self.detect_zeus_p2p()

    def detect_p2p(self):
        if self.noreply > 3:
            self.p2p = True
            log.info('P2P DETECTED: ' + str(self))

    def detect_bad_pkt_ratio(self):
        if self.pkt_ratio < 0.4:
            self.bad_pkt_ratio = True
            log.info('ABNORMAL PACKET RATIO DETECTED: ' + str(self))

    def detect_machine(self):
        timestamps = iter(flow.timestamp for flow in self.flows)
        diffs = []
        previous = next(timestamps)

        for current in timestamps:
            diff = current - previous
            if diff > 300:
                diffs.append(diff)
                previous = current
            else:
                previous = current

        if len(diffs) > 3:
            spread = statistics.stdev(diffs)
            debug('TIMINGS {0} {1} {2} {3}'.format(self.ip, self.port, spread, diffs))

            if spread < 150:
                self.machine = True
                log.info('MACHINE DETECTED: {0} {1} {2}'.format(self, spread, diffs))

    def detect_zeus_p2p(self):
        if self.p2p and (self.machine or self.bad_pkt_ratio):
            self.zeus = True
            log.warn('ZEUS P2P DETECTED: ' + str(self))


def update_monitor(flow: Flow) -> Stats:
    ip = flow.src_ip
    port = flow.src_port

    if not ip in monitor:
        stats = Stats(flow)
        monitor[ip] = {port: stats}
    elif not port in monitor[ip]:
        stats = Stats(flow)
        monitor[ip][port] = stats
    else:
        stats = monitor[ip][port]
        stats.update(flow)

    return stats


def update_timer(stats: Stats, flow: Flow):
    timer[0].append((stats, flow))


def all_stats():
    for ip, dct in monitor.items():
        for port, stats in dct.items():
            yield stats


def all_flows():
    for stats in all_stats():
        for flow in stats.flows:
            yield flow


class Collector:
    def __init__(self):
        self.transport = None
        self.msg = ipfix.message.MessageBuffer()
        print('collector created')

    def connection_made(self, transport):
        print('start', transport)
        self.transport = transport

    def datagram_received(self, data, _):
        asyncio.async(self.handle_flow(data))

    @staticmethod
    def connection_refused(exc):
        print('Connection refused:', exc)

    @staticmethod
    def connection_lost(exc):
        print('stop', exc)

    @asyncio.coroutine
    def handle_flow(self, data):
        yield from lock
        try:
            for flow in self.get_flows(data):
                debug(flow)
                if mode == 'logflows':
                    flow.log()
                elif mode == 'dumpsql':
                    flow.dump_sql()
                else:
                    stats = update_monitor(flow)
                    update_timer(stats, flow)
        except Exception as e:
            log.error(e)
        finally:
            lock.release()

    def dump_flows(self, data):
        for flow in self.get_flows(data):
            flow.log()

    def get_flows(self, data):
        try:
            self.msg.from_bytes(data)
        except ipfix.template.IpfixDecodeError:
            return

        for flow_dict in self.msg.namedict_iterator():
            flow = Flow(flow_dict)

            if not flow.src_ip:
                continue

            if flow.src_port == 0:
                continue

            yield flow


@asyncio.coroutine
def stats_logger():
    while True:
        yield from asyncio.sleep(60)
        for stats in all_stats():
            if stats.p2p:
                print(stats)
                stats.log()


@asyncio.coroutine
def cleaner():
    last = len(timer) - 1

    while True:
        yield from asyncio.sleep(timer_tick)
        yield from lock
        try:
            debug('CLEAN: ' + str(sum(len(v) for _, v in timer.items())))

            for stats, flow in timer[last]:
                ip = stats.ip
                port = stats.port
                stats.expire(flow)
                if stats.empty:
                    del monitor[ip][port]
                    if not monitor[ip]:
                        del monitor[ip]

            for i in rev_timer:
                timer[i] = timer[i - 1]

            timer[0] = []
        except Exception as e:
            log.error(e)
        finally:
            lock.release()


def main():
    loop = asyncio.get_event_loop()
    if signal is not None:
        loop.add_signal_handler(signal.SIGINT, loop.stop)
    tasks = [loop.create_datagram_endpoint(Collector, local_addr=('0.0.0.0', 4739))]
    if mode == 'detection':
        tasks.append(cleaner())
    elif mode == 'logstats':
        tasks.append(stats_logger())
        tasks.append(cleaner())
    loop.run_until_complete(asyncio.wait(tasks))
    loop.run_forever()

if __name__ == '__main__':
    main()
